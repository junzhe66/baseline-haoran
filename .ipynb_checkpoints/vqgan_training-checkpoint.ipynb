{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb7a13a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "1.11.0\n",
      "11.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "\n",
    "# also disable grad to save memory\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(DEVICE)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a56766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models.vqgan import VQModel, GumbelVQ\n",
    "\n",
    "import io\n",
    "import os, sys\n",
    "import requests\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57dc36d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "import torch\n",
    "import sys\n",
    "from nuwa_pytorch import VQGanVAE\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "def eventGeneration(start_time, obs_time = 3 ,lead_time = 6, time_interval = 30):\n",
    "    # Generate event based on starting time point, return a list: [[t-4,...,t-1,t], [t+1,...,t+72]]\n",
    "    # Get the start year, month, day, hour, minute\n",
    "    year = int(start_time[0:4])\n",
    "    month = int(start_time[4:6])\n",
    "    day = int(start_time[6:8])\n",
    "    hour = int(start_time[8:10])\n",
    "    minute = int(start_time[10:12])\n",
    "    #print(datetime(year=year, month=month, day=day, hour=hour, minute=minute))\n",
    "    times = [(datetime(year, month, day, hour, minute) + timedelta(minutes=time_interval * (x+1))) for x in range(lead_time)]\n",
    "    lead = [dt.strftime('%Y%m%d%H%M') for dt in times]\n",
    "    times = [(datetime(year, month, day, hour, minute) - timedelta(minutes=time_interval * x)) for x in range(obs_time)]\n",
    "    obs = [dt.strftime('%Y%m%d%H%M') for dt in times]\n",
    "    obs.reverse()\n",
    "    return lead, obs\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor, Compose, CenterCrop\n",
    "class radarDataset(Dataset):\n",
    "    def __init__(self, root_dir, event_times, obs_number = 3, pred_number = 6, transform=None):\n",
    "        # event_times is an array of starting time t(string)\n",
    "        # transform is the preprocessing functions\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.event_times = event_times\n",
    "        self.obs_number = obs_number\n",
    "        self.pred_number = pred_number\n",
    "    def __len__(self):\n",
    "        return len(self.event_times)\n",
    "    def __getitem__(self, idx):\n",
    "        start_time = str(self.event_times[idx])\n",
    "        time_list_pre, time_list_obs = eventGeneration(start_time, self.obs_number, self.pred_number)\n",
    "        output = []\n",
    "        time_list = time_list_obs + time_list_pre\n",
    "        #print(time_list)\n",
    "        for time in time_list:\n",
    "            year = time[0:4]\n",
    "            month = time[4:6]\n",
    "            #path = self.root_dir + year + '/' + month + '/' + 'RAD_NL25_RAC_MFBS_EM_5min_' + time + '_NL.h5'\n",
    "            path = self.root_dir + year + '/' + month + '/' + 'RAD_NL25_RAP_5min_' + time + '.h5'\n",
    "            image = np.array(h5py.File(path)['image1']['image_data'])\n",
    "            #image = np.ma.masked_where(image == 65535, image)\n",
    "            image = image[264:520,242:498]\n",
    "            image[image == 65535] = 0\n",
    "            image = image.astype('float32')\n",
    "            image = image/100*12\n",
    "            image = np.clip(image, 0, 128)\n",
    "            image = image/40\n",
    "            #image = 2*image-1 #normalize to [-1,1]\n",
    "            output.append(image)\n",
    "        output = torch.permute(torch.tensor(np.array(output)), (1, 2, 0))\n",
    "        output = self.transform(np.array(output))\n",
    "        return output\n",
    "#root_dir = '/users/hbi/data/RAD_NL25_RAC_MFBS_EM_5min/'\n",
    "#dataset = radarDataset(root_dir, [\"200808031600\"], transform = Compose([ToTensor(),CenterCrop(256)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2cdcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32183 3493 3560\n"
     ]
    }
   ],
   "source": [
    "# develop dataset\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "root_dir = '/home/hbi/RAD_NL25_RAP_5min/' \n",
    "\n",
    "df_train = pd.read_csv('/users/hbi/taming-transformers/training_Delfland08-14_20.csv', header = None)\n",
    "event_times = df_train[0].to_list()\n",
    "dataset_train = radarDataset(root_dir, event_times, transform = Compose([ToTensor()]))  \n",
    "\n",
    "df_train_s = pd.read_csv('/users/hbi/taming-transformers/training_Delfland08-14.csv', header = None)\n",
    "event_times = df_train_s[0].to_list()\n",
    "dataset_train_del = radarDataset(root_dir, event_times, transform = Compose([ToTensor()]))  \n",
    "\n",
    "df_test = pd.read_csv('/users/hbi/taming-transformers/testing_Delfland18-20.csv', header = None)\n",
    "event_times = df_test[0].to_list()\n",
    "dataset_test = radarDataset(root_dir, event_times, transform = Compose([ToTensor()]))\n",
    "\n",
    "df_vali = pd.read_csv('/users/hbi/taming-transformers/validation_Delfland15-17.csv', header = None)\n",
    "event_times = df_vali[0].to_list()\n",
    "dataset_vali = radarDataset(root_dir, event_times, transform = Compose([ToTensor()]))\n",
    "\n",
    "df_train_aa = pd.read_csv('/users/hbi/taming-transformers/training_Aa08-14.csv', header = None)\n",
    "event_times = df_train_aa[0].to_list()\n",
    "dataset_train_aa = radarDataset(root_dir, event_times, transform = Compose([ToTensor()]))  \n",
    "\n",
    "df_train_dw = pd.read_csv('/users/hbi/taming-transformers/training_Dwar08-14.csv', header = None)\n",
    "event_times = df_train_dw[0].to_list()\n",
    "dataset_train_dw = radarDataset(root_dir, event_times, transform = Compose([ToTensor()]))    \n",
    "\n",
    "df_train_re = pd.read_csv('/users/hbi/taming-transformers/training_Regge08-14.csv', header = None)\n",
    "event_times = df_train_re[0].to_list()\n",
    "dataset_train_re = radarDataset(root_dir, event_times, transform = Compose([ToTensor()]))   \n",
    "\n",
    "data_list = [dataset_train_aa, dataset_train_dw, dataset_train_del, dataset_train_re]\n",
    "train_aadedwre = torch.utils.data.ConcatDataset(data_list)\n",
    "\n",
    "print(len(dataset_train), len(dataset_test), len(dataset_vali))\n",
    "loaders = { 'train' :DataLoader(train_aadedwre, batch_size=1, shuffle=True, num_workers=8),\n",
    "            'test' :DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=8), \n",
    "           'valid' :DataLoader(dataset_vali, batch_size=1, shuffle=False, num_workers=8),\n",
    "          \n",
    "          'train_aa5' :DataLoader(dataset_train_aa, batch_size=1, shuffle=False, num_workers=8),\n",
    "          'train_dw5' :DataLoader(dataset_train_dw, batch_size=1, shuffle=False, num_workers=8),\n",
    "          'train_del5' :DataLoader(dataset_train_del, batch_size=1, shuffle=True, num_workers=8),\n",
    "          'train_re5' :DataLoader(dataset_train_re, batch_size=1, shuffle=False, num_workers=8),\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd78a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nuwa_pytorch import VQGanVAE\n",
    "from nuwa_pytorch.optimizer import get_optimizer\n",
    "vae = VQGanVAE(\n",
    "    dim = 256,\n",
    "    channels = 1,               \n",
    "    image_size = 256,           # image size\n",
    "    num_layers = 4,             # number of downsampling layers\n",
    "    num_resnet_blocks = 2,      # number of resnet blocks\n",
    "    vq_codebook_size = 1024,    # codebook size\n",
    "    vq_decay = 0.3 ,             # codebook exponential decay\n",
    "    use_hinge_loss = True,\n",
    "    use_vgg_and_gan = True\n",
    ").to(DEVICE)\n",
    "\n",
    "all_parameters = set(vae.parameters())\n",
    "discr_parameters = set(vae.discr.parameters())\n",
    "vae_parameters = all_parameters - discr_parameters\n",
    "\n",
    "lr = 1e-4\n",
    "wd = 0.001\n",
    "optim = get_optimizer(vae_parameters, lr = lr, wd = wd)\n",
    "discr_optim = get_optimizer(discr_parameters, lr = lr, wd = wd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f09166f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, 30632/ 30632,ae loss:0.0288,dis loss:0.7910\n",
      "Epoch 2, 30632/ 30632,ae loss:0.0086,dis loss:0.6853\n",
      "Epoch 3, 14019/ 30632,ae loss:0.0079,dis loss:0.4047\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, 30632/ 30632,ae loss:0.0079,dis loss:0.3118\n",
      "Epoch 4, 30632/ 30632,ae loss:0.0073,dis loss:0.1954\n",
      "Epoch 5, 30632/ 30632,ae loss:0.0068,dis loss:0.1584\n",
      "Epoch 6, 30632/ 30632,ae loss:0.0069,dis loss:0.1213\n",
      "Epoch 7, 27383/ 30632,ae loss:0.0063,dis loss:0.0677\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 30632/ 30632,ae loss:0.0062,dis loss:0.0749\n",
      "Epoch 9, 30632/ 30632,ae loss:0.0062,dis loss:0.0460\n",
      "Epoch 10, 30632/ 30632,ae loss:0.0059,dis loss:0.0394\n",
      "Epoch 11, 30632/ 30632,ae loss:0.0059,dis loss:0.0311\n",
      "Epoch 12, 30632/ 30632,ae loss:0.0057,dis loss:0.0160\n",
      "Epoch 13, 30632/ 30632,ae loss:0.0056,dis loss:0.0390\n",
      "Epoch 14, 30632/ 30632,ae loss:0.0064,dis loss:0.0648\n",
      "Epoch 15, 30632/ 30632,ae loss:0.0057,dis loss:0.0171\n",
      "Epoch 16, 30632/ 30632,ae loss:0.0055,dis loss:0.0146\n",
      "Epoch 17, 30632/ 30632,ae loss:0.0055,dis loss:0.0165\n",
      "Epoch 18, 30632/ 30632,ae loss:0.0054,dis loss:0.0198\n",
      "Epoch 19, 30632/ 30632,ae loss:0.0053,dis loss:0.0227\n",
      "Epoch 20, 30632/ 30632,ae loss:0.0054,dis loss:0.0208\n",
      "Epoch 21, 30632/ 30632,ae loss:0.0053,dis loss:0.0180\n",
      "Epoch 22, 30632/ 30632,ae loss:0.0054,dis loss:0.0388\n",
      "Epoch 23, 30632/ 30632,ae loss:0.0052,dis loss:0.0152\n",
      "Epoch 24, 30632/ 30632,ae loss:0.0052,dis loss:0.0110\n",
      "Epoch 25, 30632/ 30632,ae loss:0.0052,dis loss:0.0133\n",
      "Epoch 26, 30632/ 30632,ae loss:0.0053,dis loss:0.0140\n",
      "Epoch 27, 30632/ 30632,ae loss:0.0052,dis loss:0.0101\n",
      "Epoch 28, 30632/ 30632,ae loss:0.0055,dis loss:0.0299\n",
      "Epoch 29, 30632/ 30632,ae loss:0.0050,dis loss:0.0112\n",
      "Epoch 30, 30632/ 30632,ae loss:0.0051,dis loss:0.0117\n",
      "Epoch 31, 30632/ 30632,ae loss:0.0050,dis loss:0.0101\n",
      "Epoch 32, 30632/ 30632,ae loss:0.0049,dis loss:0.0167\n",
      "Epoch 33, 30632/ 30632,ae loss:0.0051,dis loss:0.0147\n",
      "Epoch 34, 30632/ 30632,ae loss:0.0050,dis loss:0.0153\n",
      "Epoch 35, 30632/ 30632,ae loss:0.0050,dis loss:0.0078\n",
      "Epoch 36, 30632/ 30632,ae loss:0.0049,dis loss:0.0170\n",
      "Epoch 37, 30632/ 30632,ae loss:0.0049,dis loss:0.0081\n",
      "Epoch 38, 30632/ 30632,ae loss:0.0049,dis loss:0.0243\n",
      "Epoch 39, 30632/ 30632,ae loss:0.0049,dis loss:0.0192\n",
      "Epoch 40, 30632/ 30632,ae loss:0.0048,dis loss:0.0078\n",
      "Epoch 41, 30632/ 30632,ae loss:0.0048,dis loss:0.0090\n",
      "Epoch 42, 30632/ 30632,ae loss:0.0048,dis loss:0.0062\n",
      "Epoch 43, 30632/ 30632,ae loss:0.0048,dis loss:0.0069\n",
      "Epoch 44, 30632/ 30632,ae loss:0.0047,dis loss:0.0059\n",
      "Epoch 45, 30632/ 30632,ae loss:0.0047,dis loss:0.0065\n",
      "Epoch 46, 30632/ 30632,ae loss:0.0047,dis loss:0.0085\n",
      "Epoch 47, 21329/ 30632,ae loss:0.0047,dis loss:0.0647\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, 30632/ 30632,ae loss:0.0047,dis loss:0.0476\n",
      "Epoch 48, 30632/ 30632,ae loss:0.0047,dis loss:0.0073\n",
      "Epoch 49, 30632/ 30632,ae loss:0.0047,dis loss:0.0066\n",
      "Epoch 50, 30632/ 30632,ae loss:0.0046,dis loss:0.0071\n",
      "Epoch 51, 30632/ 30632,ae loss:0.0046,dis loss:0.0064\n",
      "Epoch 52, 30632/ 30632,ae loss:0.0046,dis loss:0.0080\n",
      "Epoch 53, 30632/ 30632,ae loss:0.0046,dis loss:0.0210\n",
      "Epoch 54, 30632/ 30632,ae loss:0.0046,dis loss:0.0072\n",
      "Epoch 55, 30632/ 30632,ae loss:0.0046,dis loss:0.0053\n",
      "Epoch 56, 30632/ 30632,ae loss:0.0045,dis loss:0.0089\n",
      "Epoch 57, 30632/ 30632,ae loss:0.0045,dis loss:0.0073\n",
      "Epoch 58, 30632/ 30632,ae loss:0.0045,dis loss:0.0058\n",
      "Epoch 59, 30632/ 30632,ae loss:0.0046,dis loss:0.0115\n",
      "Epoch 60, 30632/ 30632,ae loss:0.0045,dis loss:0.0061\n",
      "Epoch 61, 14833/ 30632,ae loss:0.0046,dis loss:0.0055\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, 30632/ 30632,ae loss:0.0045,dis loss:0.0094\n",
      "Epoch 65, 30632/ 30632,ae loss:0.0045,dis loss:0.0191\n",
      "Epoch 66, 30632/ 30632,ae loss:0.0045,dis loss:0.0056\n",
      "Epoch 67, 30632/ 30632,ae loss:0.0044,dis loss:0.0064\n",
      "Epoch 68, 30632/ 30632,ae loss:0.0045,dis loss:0.0053\n",
      "Epoch 69, 30632/ 30632,ae loss:0.0044,dis loss:0.0053\n",
      "Epoch 70, 30632/ 30632,ae loss:0.0044,dis loss:0.0054\n",
      "Epoch 71, 30632/ 30632,ae loss:0.0044,dis loss:0.0104\n",
      "Epoch 72, 30632/ 30632,ae loss:0.0044,dis loss:0.0086\n",
      "Epoch 73, 30632/ 30632,ae loss:0.0044,dis loss:0.0058\n",
      "Epoch 74, 30632/ 30632,ae loss:0.0043,dis loss:0.0059\n",
      "Epoch 75, 30632/ 30632,ae loss:0.0043,dis loss:0.0060\n",
      "Epoch 76, 30632/ 30632,ae loss:0.0043,dis loss:0.0067\n",
      "Epoch 77, 30632/ 30632,ae loss:0.0043,dis loss:0.0094\n",
      "Epoch 78, 30632/ 30632,ae loss:0.0043,dis loss:0.0062\n",
      "Epoch 79, 30632/ 30632,ae loss:0.0043,dis loss:0.0050\n",
      "Epoch 80, 30632/ 30632,ae loss:0.0043,dis loss:0.0046\r"
     ]
    }
   ],
   "source": [
    "# Continue training the VQ-GAN\n",
    "import time\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "num_epochs = 80\n",
    "count = 0\n",
    "loss_sum = 0\n",
    "loss_sum_dis = 0\n",
    "loss_sum_total = 0\n",
    "total_step = len(loaders['train'])\n",
    "discr_loss = 0\n",
    "loss_ae = 0\n",
    "for g in optim.param_groups:\n",
    "    g['lr'] = 3e-6\n",
    "for g in discr_optim.param_groups:\n",
    "    g['lr'] = 3e-6\n",
    "for epoch in range(num_epochs):\n",
    "    print('')\n",
    "    #print(\"epoch {}\".format(epoch))\n",
    "    loss_sum = 0\n",
    "    loss_sum_dis = 0\n",
    "    count = 0\n",
    "    count_dis = 0\n",
    "    logit_true_sum = 0\n",
    "    logit_fake_sum = 0\n",
    "    #bar = tqdm(loaders['train_aa5'])\n",
    "    for i, images in enumerate(loaders['train']):\n",
    "        image = images[0]\n",
    "        image = image.unsqueeze(1)\n",
    "        image = image[3:4, :, :, :]\n",
    "        a = Variable(image).to(DEVICE)   # batch x\n",
    "        vae = vae.to(DEVICE)\n",
    "        \n",
    "        loss_ae = vae(a,return_loss = True)\n",
    "        discr_loss = vae(a, return_discr_loss = True)\n",
    "        #logit_fake_sum += float(fmap_discr_logits.mean())\n",
    "        #logit_true_sum += float(img_discr_logits.mean())\n",
    "        #print(fmap_discr_logits.mean(), img_discr_logits.mean())\n",
    "        loss_sum += float(loss_ae)\n",
    "        loss_sum_dis += float(discr_loss)\n",
    "        \n",
    "    \n",
    "        if 0 < (i+1) % 128 < 65:\n",
    "            (discr_loss / 64).backward()\n",
    "            count_dis += 1 \n",
    "            if count_dis % 64 == 0:\n",
    "                discr_optim.step()\n",
    "                discr_optim.zero_grad()\n",
    "        else: \n",
    "            (loss_ae / 64).backward() \n",
    "            count += 1 \n",
    "            if count % 64 == 0:\n",
    "                optim.step()\n",
    "                optim.zero_grad()\n",
    "          \n",
    "        #bar.set_postfix_str('ae loss:{:.4f},dis loss:{:.4f}'.format(float(loss_ae)\\(i+1), loss_dis))\n",
    "        print('Epoch {}, {}/ {},ae loss:{:.4f},dis loss:{:.4f}'\n",
    "              .format(epoch+1, i+1, total_step, loss_sum/(i+1), loss_sum_dis/(i+1), ), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379120fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), '/bulk/junzheyin/vae_epoch80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ce7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), '/users/junzheyin/vae_epoch80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fefcb6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30632/30632 [07:35<00:00, 67.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({376: 2353192, 3: 1273641, 206: 358837, 218: 271342, 299: 271278, 743: 259264, 922: 252244, 511: 232694, 174: 230916, 312: 223829, 89: 211835, 749: 201004, 921: 200722, 770: 183115, 856: 178675, 734: 159886, 819: 146609, 483: 140372, 437: 128119, 960: 90625, 137: 86188, 900: 86033, 928: 74788, 627: 59859, 503: 56151, 895: 48993, 954: 30671, 265: 12346, 287: 11641, 423: 6767, 600: 61, 191: 26, 860: 24, 55: 12, 392: 11, 357: 8, 908: 5, 236: 4, 644: 2, 396: 1, 862: 1, 429: 1})\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get distribution of the latent space tokens\n",
    "vae.to(DEVICE)\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "counter = Counter()\n",
    "for i, images in enumerate(tqdm(loaders['train'])):\n",
    "    images = images.unsqueeze(1)\n",
    "    a = Variable(images).to(DEVICE)   # batch x\n",
    "\n",
    "    a = a[:,:, 0:1, :, :]\n",
    "    indice = vae.get_video_indices(a)\n",
    "    #print(indice.shape)\n",
    "    counter.update(torch.flatten(indice).to('cpu').detach().numpy())\n",
    "            \n",
    "print(counter)\n",
    "print(len(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "726cc2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counter[66] = 0\n",
    "objects = counter.keys()\n",
    "y_pos = np.arange(len(objects))\n",
    "occurance = counter.values()\n",
    "\n",
    "plt.bar(y_pos, occurance, align='center', alpha=0.5)\n",
    "plt.ylabel('Occurance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "367611d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52439461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492 /3493\r"
     ]
    }
   ],
   "source": [
    "# convert dataset to latent space\n",
    "# transform all to latent space, store it\n",
    "device = 'cpu'\n",
    "name = ['train_aa5','train_dw5', 'train_del5','train_re5']\n",
    "for i, images in enumerate(loaders['test']):\n",
    "    #if i>=1: break\n",
    "    #print(i)\n",
    "    #images = images.squeeze(1)\n",
    "    a = Variable(images).to(device).unsqueeze(2).to(DEVICE)\n",
    "    #print(a.shape)\n",
    "    vae.to(DEVICE)\n",
    "    indice = vae.get_video_indices(a)\n",
    "    indice_obs = indice[:,:3, :, :]\n",
    "    indice_obs = torch.flatten(indice_obs).unsqueeze(0)\n",
    "    indice_pre = indice[:,3:, :, :]\n",
    "    indice_pre = torch.flatten(indice_pre).unsqueeze(0)\n",
    "    #print(indice_obs.shape, indice_pre.shape)\n",
    "    torch.save([indice_obs,indice_pre], '/bulk/junzheyin/test1820/testset'+str(i)+'.pt')\n",
    "    print(i, '/{}'.format(len(loaders['test'])), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805dfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc237f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fa1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
